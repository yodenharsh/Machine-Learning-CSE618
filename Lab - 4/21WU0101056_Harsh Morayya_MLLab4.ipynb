{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective 1: Design a simple perceptron without using any library functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Initial Weights:  [0.27685064004629956, -0.9783287312534501, -0.7949347483259039]\n",
      "Sum:  -1\n",
      "DESIRED  1\n",
      "ERROR  2\n",
      "New Weights:  [-0.02, -0.02, 0.02]\n",
      "----------------------------------------------------------------------\n",
      "Initial Weights:  [-0.02, -0.02, 0.02]\n",
      "Sum:  1\n",
      "DESIRED  1\n",
      "SUCCESS\n",
      "New Weights:  []\n",
      "Iterations:  1\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "\n",
    "gInputs = []\n",
    "\n",
    "class Perceptron():\n",
    "\n",
    "    def setWeights(self, weightNum):\n",
    "        weights = []\n",
    "        for i in range(weightNum):\n",
    "            weights.append(random.rand() * 2 - 1)\n",
    "        return weights\n",
    "\n",
    "    def activate(self, weights, inputs):\n",
    "        global gInputs\n",
    "        gInputs = inputs\n",
    "        sum = 0\n",
    "        for i in range(len(inputs)):\n",
    "            sum += weights[i] * inputs[i]\n",
    "        if sum >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def updateWeights(self, learningRate, desired, sum):\n",
    "        global gInputs\n",
    "        newWeights = []\n",
    "        print (\"DESIRED \", desired)\n",
    "        if desired != sum:\n",
    "            error = desired - sum\n",
    "            print(\"ERROR \", error)\n",
    "            length = len(gInputs)\n",
    "            for i in range(0, length):\n",
    "                newWeights.append(learningRate * error * gInputs[i])\n",
    "            return {'newWeights': newWeights, 'iterate': True}\n",
    "        else:\n",
    "            print(\"SUCCESS\")\n",
    "            return {'newWeights': newWeights, 'iterate': False}\n",
    "        \n",
    "inputs = [-1,-1,1]\n",
    "weightNum = len(inputs)\n",
    "weights = 0\n",
    "learningRate = 0.01\n",
    "desired = 1\n",
    "iterate = True\n",
    "iterCount = 0\n",
    "\n",
    "ptron = Perceptron()\n",
    "weights = ptron.setWeights(weightNum)\n",
    "while iterate:\n",
    "    print(\"-\"*70)\n",
    "    print(\"Initial Weights: \", weights)\n",
    "    sum = ptron.activate(weights, inputs)\n",
    "    print(\"Sum: \", sum)\n",
    "    returned = ptron.updateWeights(learningRate, desired, sum)\n",
    "    print(\"New Weights: \", returned['newWeights'])\n",
    "    if not returned['iterate']:\n",
    "        print(\"Iterations: \", iterCount)\n",
    "        iterate = False\n",
    "        print(\"-\"*70)\n",
    "    else:\n",
    "        weights = returned['newWeights']\n",
    "        iterCount = iterCount + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective 2 - Creating a dataset using rand function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([\n",
    "    [random.randint(1, 500) for _ in range(750)],\n",
    "    [random.randint(250, 600) for _ in range(750)]\n",
    "])\n",
    "X = X.T  # Transpose to have shape (750, 2)\n",
    "y = np.array([random.randint(1, 24) for _ in range(750)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective 3 - i) Using the synthesized dataset, implement an ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "17/17 - 1s - loss: 201.0600 - mean_squared_error: 201.0600 - val_loss: 207.6643 - val_mean_squared_error: 207.6643 - 1s/epoch - 71ms/step\n",
      "Epoch 2/50\n",
      "17/17 - 0s - loss: 183.6464 - mean_squared_error: 183.6464 - val_loss: 185.4725 - val_mean_squared_error: 185.4725 - 68ms/epoch - 4ms/step\n",
      "Epoch 3/50\n",
      "17/17 - 0s - loss: 160.1468 - mean_squared_error: 160.1468 - val_loss: 156.8612 - val_mean_squared_error: 156.8612 - 86ms/epoch - 5ms/step\n",
      "Epoch 4/50\n",
      "17/17 - 0s - loss: 130.5539 - mean_squared_error: 130.5539 - val_loss: 121.6181 - val_mean_squared_error: 121.6181 - 70ms/epoch - 4ms/step\n",
      "Epoch 5/50\n",
      "17/17 - 0s - loss: 97.6689 - mean_squared_error: 97.6689 - val_loss: 87.0832 - val_mean_squared_error: 87.0832 - 70ms/epoch - 4ms/step\n",
      "Epoch 6/50\n",
      "17/17 - 0s - loss: 71.7170 - mean_squared_error: 71.7170 - val_loss: 63.4615 - val_mean_squared_error: 63.4615 - 63ms/epoch - 4ms/step\n",
      "Epoch 7/50\n",
      "17/17 - 0s - loss: 58.8295 - mean_squared_error: 58.8295 - val_loss: 55.5542 - val_mean_squared_error: 55.5542 - 65ms/epoch - 4ms/step\n",
      "Epoch 8/50\n",
      "17/17 - 0s - loss: 55.4980 - mean_squared_error: 55.4980 - val_loss: 55.0125 - val_mean_squared_error: 55.0125 - 61ms/epoch - 4ms/step\n",
      "Epoch 9/50\n",
      "17/17 - 0s - loss: 55.1462 - mean_squared_error: 55.1462 - val_loss: 55.2530 - val_mean_squared_error: 55.2530 - 66ms/epoch - 4ms/step\n",
      "Epoch 10/50\n",
      "17/17 - 0s - loss: 54.6077 - mean_squared_error: 54.6077 - val_loss: 55.6086 - val_mean_squared_error: 55.6086 - 68ms/epoch - 4ms/step\n",
      "Epoch 11/50\n",
      "17/17 - 0s - loss: 54.1911 - mean_squared_error: 54.1911 - val_loss: 55.0174 - val_mean_squared_error: 55.0174 - 62ms/epoch - 4ms/step\n",
      "Epoch 12/50\n",
      "17/17 - 0s - loss: 53.8476 - mean_squared_error: 53.8476 - val_loss: 55.5062 - val_mean_squared_error: 55.5062 - 58ms/epoch - 3ms/step\n",
      "Epoch 13/50\n",
      "17/17 - 0s - loss: 53.4556 - mean_squared_error: 53.4556 - val_loss: 55.1624 - val_mean_squared_error: 55.1624 - 56ms/epoch - 3ms/step\n",
      "Epoch 14/50\n",
      "17/17 - 0s - loss: 53.2324 - mean_squared_error: 53.2324 - val_loss: 54.4052 - val_mean_squared_error: 54.4052 - 57ms/epoch - 3ms/step\n",
      "Epoch 15/50\n",
      "17/17 - 0s - loss: 52.9627 - mean_squared_error: 52.9627 - val_loss: 55.2978 - val_mean_squared_error: 55.2978 - 59ms/epoch - 3ms/step\n",
      "Epoch 16/50\n",
      "17/17 - 0s - loss: 52.3668 - mean_squared_error: 52.3668 - val_loss: 55.0535 - val_mean_squared_error: 55.0535 - 60ms/epoch - 4ms/step\n",
      "Epoch 17/50\n",
      "17/17 - 0s - loss: 52.2180 - mean_squared_error: 52.2180 - val_loss: 54.1940 - val_mean_squared_error: 54.1940 - 62ms/epoch - 4ms/step\n",
      "Epoch 18/50\n",
      "17/17 - 0s - loss: 51.9285 - mean_squared_error: 51.9285 - val_loss: 54.5274 - val_mean_squared_error: 54.5274 - 66ms/epoch - 4ms/step\n",
      "Epoch 19/50\n",
      "17/17 - 0s - loss: 51.6739 - mean_squared_error: 51.6739 - val_loss: 54.4082 - val_mean_squared_error: 54.4082 - 67ms/epoch - 4ms/step\n",
      "Epoch 20/50\n",
      "17/17 - 0s - loss: 51.4192 - mean_squared_error: 51.4192 - val_loss: 54.2815 - val_mean_squared_error: 54.2815 - 67ms/epoch - 4ms/step\n",
      "Epoch 21/50\n",
      "17/17 - 0s - loss: 51.0857 - mean_squared_error: 51.0857 - val_loss: 54.0175 - val_mean_squared_error: 54.0175 - 65ms/epoch - 4ms/step\n",
      "Epoch 22/50\n",
      "17/17 - 0s - loss: 50.9700 - mean_squared_error: 50.9700 - val_loss: 54.3071 - val_mean_squared_error: 54.3071 - 56ms/epoch - 3ms/step\n",
      "Epoch 23/50\n",
      "17/17 - 0s - loss: 50.7657 - mean_squared_error: 50.7657 - val_loss: 54.0844 - val_mean_squared_error: 54.0844 - 57ms/epoch - 3ms/step\n",
      "Epoch 24/50\n",
      "17/17 - 0s - loss: 50.5512 - mean_squared_error: 50.5512 - val_loss: 54.0482 - val_mean_squared_error: 54.0482 - 58ms/epoch - 3ms/step\n",
      "Epoch 25/50\n",
      "17/17 - 0s - loss: 50.3926 - mean_squared_error: 50.3926 - val_loss: 53.9881 - val_mean_squared_error: 53.9881 - 60ms/epoch - 4ms/step\n",
      "Epoch 26/50\n",
      "17/17 - 0s - loss: 50.3234 - mean_squared_error: 50.3234 - val_loss: 54.0536 - val_mean_squared_error: 54.0536 - 57ms/epoch - 3ms/step\n",
      "Epoch 27/50\n",
      "17/17 - 0s - loss: 50.2225 - mean_squared_error: 50.2225 - val_loss: 54.2518 - val_mean_squared_error: 54.2518 - 55ms/epoch - 3ms/step\n",
      "Epoch 28/50\n",
      "17/17 - 0s - loss: 50.1222 - mean_squared_error: 50.1222 - val_loss: 54.2745 - val_mean_squared_error: 54.2745 - 57ms/epoch - 3ms/step\n",
      "Epoch 29/50\n",
      "17/17 - 0s - loss: 49.9679 - mean_squared_error: 49.9679 - val_loss: 53.9990 - val_mean_squared_error: 53.9990 - 57ms/epoch - 3ms/step\n",
      "Epoch 30/50\n",
      "17/17 - 0s - loss: 49.7519 - mean_squared_error: 49.7519 - val_loss: 53.8135 - val_mean_squared_error: 53.8135 - 56ms/epoch - 3ms/step\n",
      "Epoch 31/50\n",
      "17/17 - 0s - loss: 49.6363 - mean_squared_error: 49.6363 - val_loss: 54.3726 - val_mean_squared_error: 54.3726 - 58ms/epoch - 3ms/step\n",
      "Epoch 32/50\n",
      "17/17 - 0s - loss: 49.4857 - mean_squared_error: 49.4857 - val_loss: 54.2814 - val_mean_squared_error: 54.2814 - 57ms/epoch - 3ms/step\n",
      "Epoch 33/50\n",
      "17/17 - 0s - loss: 49.4330 - mean_squared_error: 49.4330 - val_loss: 54.1283 - val_mean_squared_error: 54.1283 - 60ms/epoch - 4ms/step\n",
      "Epoch 34/50\n",
      "17/17 - 0s - loss: 49.4900 - mean_squared_error: 49.4900 - val_loss: 54.7054 - val_mean_squared_error: 54.7054 - 72ms/epoch - 4ms/step\n",
      "Epoch 35/50\n",
      "17/17 - 0s - loss: 49.2911 - mean_squared_error: 49.2911 - val_loss: 53.9557 - val_mean_squared_error: 53.9557 - 61ms/epoch - 4ms/step\n",
      "Epoch 36/50\n",
      "17/17 - 0s - loss: 49.2462 - mean_squared_error: 49.2462 - val_loss: 54.3712 - val_mean_squared_error: 54.3712 - 56ms/epoch - 3ms/step\n",
      "Epoch 37/50\n",
      "17/17 - 0s - loss: 49.1184 - mean_squared_error: 49.1184 - val_loss: 53.9633 - val_mean_squared_error: 53.9633 - 55ms/epoch - 3ms/step\n",
      "Epoch 38/50\n",
      "17/17 - 0s - loss: 49.0979 - mean_squared_error: 49.0979 - val_loss: 54.2331 - val_mean_squared_error: 54.2331 - 66ms/epoch - 4ms/step\n",
      "Epoch 39/50\n",
      "17/17 - 0s - loss: 49.0078 - mean_squared_error: 49.0078 - val_loss: 54.2065 - val_mean_squared_error: 54.2065 - 60ms/epoch - 4ms/step\n",
      "Epoch 40/50\n",
      "17/17 - 0s - loss: 49.0371 - mean_squared_error: 49.0371 - val_loss: 53.9133 - val_mean_squared_error: 53.9133 - 64ms/epoch - 4ms/step\n",
      "Epoch 41/50\n",
      "17/17 - 0s - loss: 49.1107 - mean_squared_error: 49.1107 - val_loss: 54.9789 - val_mean_squared_error: 54.9789 - 63ms/epoch - 4ms/step\n",
      "Epoch 42/50\n",
      "17/17 - 0s - loss: 49.0108 - mean_squared_error: 49.0108 - val_loss: 54.2715 - val_mean_squared_error: 54.2715 - 68ms/epoch - 4ms/step\n",
      "Epoch 43/50\n",
      "17/17 - 0s - loss: 48.8480 - mean_squared_error: 48.8480 - val_loss: 54.5410 - val_mean_squared_error: 54.5410 - 60ms/epoch - 4ms/step\n",
      "Epoch 44/50\n",
      "17/17 - 0s - loss: 48.8783 - mean_squared_error: 48.8783 - val_loss: 54.2550 - val_mean_squared_error: 54.2550 - 55ms/epoch - 3ms/step\n",
      "Epoch 45/50\n",
      "17/17 - 0s - loss: 48.7801 - mean_squared_error: 48.7801 - val_loss: 54.7075 - val_mean_squared_error: 54.7075 - 58ms/epoch - 3ms/step\n",
      "Epoch 46/50\n",
      "17/17 - 0s - loss: 48.6946 - mean_squared_error: 48.6946 - val_loss: 54.4606 - val_mean_squared_error: 54.4606 - 57ms/epoch - 3ms/step\n",
      "Epoch 47/50\n",
      "17/17 - 0s - loss: 48.7595 - mean_squared_error: 48.7595 - val_loss: 54.7946 - val_mean_squared_error: 54.7946 - 57ms/epoch - 3ms/step\n",
      "Epoch 48/50\n",
      "17/17 - 0s - loss: 48.5908 - mean_squared_error: 48.5908 - val_loss: 54.6030 - val_mean_squared_error: 54.6030 - 56ms/epoch - 3ms/step\n",
      "Epoch 49/50\n",
      "17/17 - 0s - loss: 49.0530 - mean_squared_error: 49.0530 - val_loss: 54.1436 - val_mean_squared_error: 54.1436 - 56ms/epoch - 3ms/step\n",
      "Epoch 50/50\n",
      "17/17 - 0s - loss: 48.7083 - mean_squared_error: 48.7083 - val_loss: 54.6938 - val_mean_squared_error: 54.6938 - 58ms/epoch - 3ms/step\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 49.1141 - mean_squared_error: 49.1141\n",
      "Mean Squared Error on Test Set: 49.11\n",
      "Epoch 1: Train MSE: 201.06\n",
      "Epoch 2: Train MSE: 183.65\n",
      "Epoch 3: Train MSE: 160.15\n",
      "Epoch 4: Train MSE: 130.55\n",
      "Epoch 5: Train MSE: 97.67\n",
      "Epoch 6: Train MSE: 71.72\n",
      "Epoch 7: Train MSE: 58.83\n",
      "Epoch 8: Train MSE: 55.50\n",
      "Epoch 9: Train MSE: 55.15\n",
      "Epoch 10: Train MSE: 54.61\n",
      "Epoch 11: Train MSE: 54.19\n",
      "Epoch 12: Train MSE: 53.85\n",
      "Epoch 13: Train MSE: 53.46\n",
      "Epoch 14: Train MSE: 53.23\n",
      "Epoch 15: Train MSE: 52.96\n",
      "Epoch 16: Train MSE: 52.37\n",
      "Epoch 17: Train MSE: 52.22\n",
      "Epoch 18: Train MSE: 51.93\n",
      "Epoch 19: Train MSE: 51.67\n",
      "Epoch 20: Train MSE: 51.42\n",
      "Epoch 21: Train MSE: 51.09\n",
      "Epoch 22: Train MSE: 50.97\n",
      "Epoch 23: Train MSE: 50.77\n",
      "Epoch 24: Train MSE: 50.55\n",
      "Epoch 25: Train MSE: 50.39\n",
      "Epoch 26: Train MSE: 50.32\n",
      "Epoch 27: Train MSE: 50.22\n",
      "Epoch 28: Train MSE: 50.12\n",
      "Epoch 29: Train MSE: 49.97\n",
      "Epoch 30: Train MSE: 49.75\n",
      "Epoch 31: Train MSE: 49.64\n",
      "Epoch 32: Train MSE: 49.49\n",
      "Epoch 33: Train MSE: 49.43\n",
      "Epoch 34: Train MSE: 49.49\n",
      "Epoch 35: Train MSE: 49.29\n",
      "Epoch 36: Train MSE: 49.25\n",
      "Epoch 37: Train MSE: 49.12\n",
      "Epoch 38: Train MSE: 49.10\n",
      "Epoch 39: Train MSE: 49.01\n",
      "Epoch 40: Train MSE: 49.04\n",
      "Epoch 41: Train MSE: 49.11\n",
      "Epoch 42: Train MSE: 49.01\n",
      "Epoch 43: Train MSE: 48.85\n",
      "Epoch 44: Train MSE: 48.88\n",
      "Epoch 45: Train MSE: 48.78\n",
      "Epoch 46: Train MSE: 48.69\n",
      "Epoch 47: Train MSE: 48.76\n",
      "Epoch 48: Train MSE: 48.59\n",
      "Epoch 49: Train MSE: 49.05\n",
      "Epoch 50: Train MSE: 48.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(2,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output layer for regression (single neuron)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=2)\n",
    "\n",
    "loss, test_mse = model.evaluate(X_test, y_test)\n",
    "print(f\"Mean Squared Error on Test Set: {test_mse:.2f}\")\n",
    "\n",
    "# Print training accuracy at each epoch\n",
    "for epoch, train_mse in enumerate(history.history['mean_squared_error'], 1):\n",
    "    print(f\"Epoch {epoch}: Train MSE: {train_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective 3 - ii) Using a Kaggle dataset, implement an ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Churn_Modelling.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15647311</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15619304</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15701354</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15737888</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15606229</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15569892</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15584532</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15682355</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15628319</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  CustomerId  EstimatedSalary  Exited  \n",
       "0             1    15634602        101348.88       1  \n",
       "1             0    15647311        112542.58       0  \n",
       "2             1    15619304        113931.57       1  \n",
       "3             0    15701354         93826.63       0  \n",
       "4             1    15737888         79084.10       0  \n",
       "...         ...         ...              ...     ...  \n",
       "9995          1    15606229         96270.64       0  \n",
       "9996          1    15569892        101699.77       0  \n",
       "9997          0    15584532         42085.58       1  \n",
       "9998          1    15682355         92888.52       1  \n",
       "9999          1    15628319         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1=df.iloc[:,[3,4,5,6,7,8,9,10,1,12,13]]\n",
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6844/496365326.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data1[\"Geography\"]=l1.fit_transform(data1[\"Geography\"])\n",
      "/tmp/ipykernel_6844/496365326.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data1[\"Gender\"]=l1.fit_transform(data1[\"Gender\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15647311</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15619304</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15701354</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15737888</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15606229</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15569892</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15584532</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15682355</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15628319</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619          0       0   42       2       0.00              1   \n",
       "1             608          2       0   41       1   83807.86              1   \n",
       "2             502          0       0   42       8  159660.80              3   \n",
       "3             699          0       0   39       1       0.00              2   \n",
       "4             850          2       0   43       2  125510.82              1   \n",
       "...           ...        ...     ...  ...     ...        ...            ...   \n",
       "9995          771          0       1   39       5       0.00              2   \n",
       "9996          516          0       1   35      10   57369.61              1   \n",
       "9997          709          0       0   36       7       0.00              1   \n",
       "9998          772          1       1   42       3   75075.31              2   \n",
       "9999          792          0       0   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  CustomerId  EstimatedSalary  Exited  \n",
       "0             1    15634602        101348.88       1  \n",
       "1             0    15647311        112542.58       0  \n",
       "2             1    15619304        113931.57       1  \n",
       "3             0    15701354         93826.63       0  \n",
       "4             1    15737888         79084.10       0  \n",
       "...         ...         ...              ...     ...  \n",
       "9995          1    15606229         96270.64       0  \n",
       "9996          1    15569892        101699.77       0  \n",
       "9997          0    15584532         42085.58       1  \n",
       "9998          1    15682355         92888.52       1  \n",
       "9999          1    15628319         38190.78       0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Label encoding 'Gender' and 'Geography'\n",
    "\n",
    "l1 = LabelEncoder()\n",
    "data1[\"Geography\"]=l1.fit_transform(data1[\"Geography\"])\n",
    "data1[\"Gender\"]=l1.fit_transform(data1[\"Gender\"])\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data1.iloc[:,:-1].values\n",
    "y=data1.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.538     , 0.        , 0.        , ..., 1.        , 0.27561613,\n",
       "        0.50673489],\n",
       "       [0.516     , 1.        , 0.        , ..., 0.        , 0.32645436,\n",
       "        0.56270874],\n",
       "       [0.304     , 0.        , 0.        , ..., 1.        , 0.21442143,\n",
       "        0.56965435],\n",
       "       ...,\n",
       "       [0.718     , 0.        , 0.        , ..., 0.        , 0.07532731,\n",
       "        0.21039009],\n",
       "       [0.844     , 0.5       , 1.        , ..., 1.        , 0.46663653,\n",
       "        0.46442905],\n",
       "       [0.884     , 0.        , 0.        , ..., 1.        , 0.25048302,\n",
       "        0.19091423]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Scaling  use Normalization\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "p=scaler.fit_transform(x)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "ann = Sequential()\n",
    "\n",
    "# Input layer\n",
    "ann.add(Dense(units=6, activation='relu'))\n",
    "\n",
    "ann.add(Dense(units=6, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "ann.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the ANN to training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 2s 3ms/step - loss: 43033.6680 - accuracy: 0.5620\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.7961\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5986 - accuracy: 0.7961\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5654 - accuracy: 0.7961\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5431 - accuracy: 0.7961\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5283 - accuracy: 0.7961\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5190 - accuracy: 0.7961\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5132 - accuracy: 0.7961\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5098 - accuracy: 0.7961\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5079 - accuracy: 0.7961\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5068 - accuracy: 0.7961\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5062 - accuracy: 0.7961\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5060 - accuracy: 0.7961\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7961\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7961\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7961\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7961\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7961\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7961\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7961\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7961\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7961\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7961\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7961\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7961\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.7961\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7961\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7961\n"
     ]
    }
   ],
   "source": [
    "history = ann.fit(x_train, y_train, batch_size = 32, epochs = 100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.7970\n",
      "Accuracy:  0.796999990940094\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
    "print('Accuracy: ',ann.evaluate(x_test,y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1594    0]\n",
      " [ 406    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79.7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "Confusion_Matrix=metrics.confusion_matrix(y_test,y_pred)\n",
    "cm_display=metrics.ConfusionMatrixDisplay(Confusion_Matrix)\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
